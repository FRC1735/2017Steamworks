// RobotBuilder Version: 2.0
//
// This file was generated by RobotBuilder. It contains sections of
// code that are automatically generated and assigned by robotbuilder.
// These sections will be updated in the future when you export to
// Java from RobotBuilder. Do not put any code or make any change in
// the blocks indicating autogenerated code or it will be lost on an
// update. Deleting the comments indicating the section will prevent
// it from being updated in the future.


package org.usfirst.frc1735.Steamworks2017.subsystems;

import org.usfirst.frc1735.Steamworks2017.Robot;
import org.usfirst.frc1735.Steamworks2017.RobotMap;
import org.usfirst.frc1735.Steamworks2017.commands.*;

import com.ctre.CANTalon;
import com.ctre.CANTalon.FeedbackDevice;
import com.ctre.CANTalon.TalonControlMode;

import edu.wpi.first.wpilibj.Relay;
import edu.wpi.first.wpilibj.command.Subsystem;
import edu.wpi.first.wpilibj.networktables.NetworkTable;
import edu.wpi.first.wpilibj.smartdashboard.SmartDashboard;


/**
 *
 */
public class Turret extends Subsystem {

    // BEGIN AUTOGENERATED CODE, SOURCE=ROBOTBUILDER ID=CONSTANTS

    // END AUTOGENERATED CODE, SOURCE=ROBOTBUILDER ID=CONSTANTS

    // BEGIN AUTOGENERATED CODE, SOURCE=ROBOTBUILDER ID=DECLARATIONS
    private final CANTalon turretTurner = RobotMap.turretTurretTurner;
    private final Relay cameraLightRelay = RobotMap.turretCameraLightRelay;

    // END AUTOGENERATED CODE, SOURCE=ROBOTBUILDER ID=DECLARATIONS

    // We need a constructor
	public Turret() {		
	    // Get a pointer to the networkTable.  "BoilerVision" is the name we entered into the publish box in GRIP
	    m_boilerTable = NetworkTable.getTable("GRIP/BoilerVision");
		}

    // Put methods for controlling this subsystem
    // here. Call these from Commands.

    public void initDefaultCommand() {
        // BEGIN AUTOGENERATED CODE, SOURCE=ROBOTBUILDER ID=DEFAULT_COMMAND


    // END AUTOGENERATED CODE, SOURCE=ROBOTBUILDER ID=DEFAULT_COMMAND

        // Set the default command for a subsystem here.
        setDefaultCommand(new TurretWithJoystick());
    }
    
    // Routine to initialize the run-time parameters for the Talon PID controller.
    // Example taken from CTRE github PositionClosedLoop
    // WE don't want to do this at construction time, so make RobotInit() call this function.
    public void turretInit() {
    	if (false) {
    	// Choose the sensor and sensor dirction
    	turretTurner.setFeedbackDevice(FeedbackDevice.AnalogEncoder);
    	turretTurner.reverseSensor(false); //Assume no inversion at this time.
    	turretTurner.configPotentiometerTurns(1); // Assume a 1:1 ratio of turret to encoder rotations
    	turretTurner.configNominalOutputVoltage(+0f,  -0f);
    	turretTurner.configPeakOutputVoltage(+12f,  -12f);
    	
    	/* set the allowable closed-loop error,
         * Closed-Loop output will be neutral within this range.
         * See Table in Section 17.2.1 for native units per rotation. 
         */
        turretTurner.setAllowableClosedLoopErr(0); /* always servo */
        /* set closed loop gains in slot0 */
        turretTurner.setProfile(0);
        turretTurner.setF(0.0);
        turretTurner.setP(0.1);
        turretTurner.setI(0.0); 
        turretTurner.setD(0.0);
        
        // Because we have limited motion in either direction, we may need to specify soft limits on the absolute encoder value.
        // The actual limit values will probably vary due to assembly (far left edge might not be exactly zero>)
        // Units are in rotations
        turretTurner.setForwardSoftLimit(m_forwardSoftLimit);
        turretTurner.enableForwardSoftLimit(true);
        turretTurner.setReverseSoftLimit(m_reverseSoftLimit);
        turretTurner.enableReverseSoftLimit(true);
        
        // Set the mode to be position-based
        turretTurner.changeControlMode(TalonControlMode.Position);
        // Must set an initial setpoint as well
        turretTurner.set((m_forwardSoftLimit+m_reverseSoftLimit)/2); // Center between the absolute left and right
        
        // This is also a good place to publish the current vision target centerpoint (for tuning)
        SmartDashboard.putNumber("Boiler Center Offset (pixels)", m_targetCenterOffset);
    	}
	}    	
    	
    //-----------------------
    // operate
    //-----------------------
    // This function is the main command for the turret.
    // it is called by the subsystem defaultCommand every DS time loop (~20ms)
    // The algorithm is:
    // - Grab the latest position data from the vision coprocessor
    // - Calculate the amount we are "off" from being centered
    // - grab our current/absolute position
    // - calculate a new absolute position to get us centered based on the current offset
    // - Provide the new absolute position as the new setpoint to the PID
    
    // The PID itself runs in hardware on the TalonSRX and iterates at a rate much faster than the camera data refresh or the 20ms DS loop.
    // So, we need to be careful not to send stale camera data to the PID if it's already close to the actual goal based on the last "good" snapshot.
    // Not sure how to limit this unless we only get snapshots when we think we have gotten onTarget from the last snapshot
    public void operate() {
    	double targetAngle;
    	double currentSetpoint = turretTurner.getSetpoint();
    	// Are we actively targeting? And have we reached the last snapshot's target position?  if so, calculate a new target
    	if (this.isVisionEnabled() && this.onTarget()) {
        	// Query the camera info to get our angle of error from the target.
        	// If no target is currently visible, returns an error of zero (this prevents us from spinning around aimlessly if we lose the target)
        	// @FIXME:  Eventually, some kind of algorithm to help with lost vision target would be good-- do we actually search for it?
        	double errorAngle = getErrorAngle(); // Need to be careful about the sign.  Assume that lower numbers are to the left (relative to shooter).
        	System.out.println("Turret currently is off target by " + errorAngle + " degrees.");
        	double currentAngle = turretTurner.get()*360; // go relative to our current position (which might not QUITE be the setpoint)
        	targetAngle = currentAngle + errorAngle; // if error is negative we will turn to the left.
    	}
    	else {
    		// either we are not targeting, or we are in motion right now; keep the current setpoint that we defaulted to at the top of the function
        	targetAngle = currentSetpoint*360; // convert setpoint's "rotations" into "Degrees"
		}
    	
    	System.out.println("New target angle is " + targetAngle + " or an absolute rotational position of " + targetAngle/360);
    	// Make the targetAngle the new setpoint (Must do this periodically to avoid Motor safety timeouts!)
    	// However, the PID takes ROTATIONS as the unit of measurement.
    	// So, if one rotation is 360 degrees, then we simply divide the angle by 360.
    	// @FIXME: Again, this assumes the left edge is at zero; may need a correction factor throughout this function...
    	turretTurner.set(targetAngle/360);
    }
    
    // Returns true if we are actively using the turret (enables vision snapshots and the HW PID controller)
    public boolean isVisionEnabled() {
    	return m_visionEnabled;
    }
    
    // Set the mode (active = true)
    public void setVisionEnable(boolean isEnabled) {
    	m_visionEnabled = isEnabled;
    }
        
    // Return if we think the PID is at its target setpoint right now
    public boolean onTarget() {
    	// Error is reported in (Fractional) rotations with one rotation being 1024 units.
    	// Therefore, if we want error of 1%, we want the reported error to be <= 10.24
    	if (Math.abs(turretTurner.getClosedLoopError()) <= 10.24) {
    		return true;
    	}
    	else {
    		return false;
    	}
    }
    
    //----------------------------------
    // getErrorAngle()
    //----------------------------------
    // This is the "meat" of the vision processing system.
    // Grab the current "centered X" position stuffed into the NetworkTable by the coprocessor,
    // and calculate how far off-center we are.
    public double getErrorAngle() {
    	// First, find out how far off center we are in the image.
    	// The desired centerline is Xres/2 + our compensation for camera vs shooter location
    	// Get the current setpoint from SmartDashboard (so it can be tuned without recompiling)
    	double desiredCenter = m_xRes/2 + SmartDashboard.getNumber("Boiler Center Offset (pixels)", m_targetCenterOffset); // Default to the compiled value if entry not found
    	
    	// Get the raw position and object width from NetworkTables:
    	double [] rawData = getRawTargetData();
    	double currentXPos = rawData[0];
    	// double xWid = rawData[1]; // Don't need this for angle calculation.
    	    	
    	// Given a measured angle Theta from image center to edge of FOV
    	// if the raw pixel distance over that angle is XRes/2=160, then each pixel off-center is (e.g.) 30.521/160 = 0.19075625 degrees
    	// Our answer is therefore is the pixel error multiplied by degrees_per_pixel:
    	double pixelError = currentXPos - desiredCenter;
    	return (pixelError * (m_cameraTheta/(m_xRes/2)));
    	
    	
    }
    
    // Return data for a single contour (the Table presents an array of each piece of data, unfortunately... have to turn it sideways
    // [0]: the pixel position of the center of the target's X axis
    // [1]: the width of the target (total width)
    public double[] getRawTargetData() {
    	double xPos;
    	double xWid; // components of our return value
    	
    	// 1) Get the current list of targets found.  There might be more than one visible at a time if our processing is noisy,
    	//    or if we can't combine the two tape strips into a single blob on the coprocessor.
    	//    It might report no targets if the lighting isn't right, or the target is outside the camera's field of view.
       	// First step: get the vision system data for the target

    	// Get all needed table items at (roughly) the same time, to minimize (but not eliminate) the chance table updates between reads.
    	// (could end up with different array sizes)
    	double[] defaultValue = new double[0]; // set up a default value in case the table isn't published yet
    	double[] targetX = m_boilerTable.getNumberArray("centerX", defaultValue);    	
		double[] width = m_boilerTable.getNumberArray("width", defaultValue);
		if (targetX.length != width.length) {
			// here the table updated in the middle and the number of elements detected is not consistent; we'll have to punt.
			// (Yes, it could have updated to the same number of objects, but different objects.  There is no way to detect that at all)
			// This is just to indicate noise where the number of identified contours is varying rapidly, possibly between none and one.
			System.out.println("NetworkTable udpated in the middle of getRawTargetData; may have inconsistent datapoints!");
		}
		// Choose the first object, if one was found.
    	if (targetX.length==0) {
    		// We didn't find a valid x position to use.
    		// Return a perfectly centered answer so that the system doesn't try to adapt
    		// We also have to compensate for offset between the camera image and the actual robot.
    		xPos = ((m_xRes/2) + SmartDashboard.getNumber("Boiler Center Offset (pixels)", m_targetCenterOffset));
    	}
    	else {
    		xPos = targetX[0]; // Use the first Xposition value
    	}
    	if (width.length==0) {
    		// No valid width.  punt and set the width to some value that matches what we'd see in auto firing from the hopper...
    		xWid = 53; // Measured one data point at approximately the position and height that auto would shoot from.  Probably needs refinement.
    	}
    	else {
    		xWid = width[0]; // Use the first width value
    	}
	    	
	    	
    	// For initial debug, just print out the table so we can see what's going on
    	m_sb.append("NetworkTable data:  centerX: ");
    	for (double xval : targetX) { // for each target found,
    		m_sb.append(xval + " ");
    	}
		System.out.print(m_sb.toString());
		m_sb.setLength(0);

		// Print the return value for debug
		System.out.println("Calculated pixel xPos = " + xPos + ", xWid = " + xWid);
		
    	
	    // Return an array of the answers
	    double[] rawData = {xPos, xWid};
	    return rawData;
     }

    public double calculateDistanceFromCamera(double targetWidthPixels) {
    	//implements this equation:
    	// d = Tinches*FOVpixel/(2*Tpixel*tan(CameraTheta))
    	// where FOVpixel is represented by m_xRes.
    	double distance, manualDistance;
    	
    	// If we don't see a target, the width will be zero.
    	// Punt by setting the distance to be something in the middle...
    	// choose the most likely distance for autonomous, so a failure of the camera still has a good chance of working.
    	// Something like 48" sounds good.
    	if (targetWidthPixels > 0) {
    		// @FIXME:  last year the math gave the wrong answer, and we had to hand-calculate the number.
    		// print both for debug purposes until we know this is resolved...
    		distance = (m_targetWidthInches*m_xRes)/(2*targetWidthPixels*Math.tan(m_cameraTheta));
    		// Now calculate based on manual analysis of the above data:
    		manualDistance = 8141.9576/targetWidthPixels;
    		Robot.dbgPrintln("For input width " + targetWidthPixels + "\tCalculated distance is " + distance + "\tManually calculated distance is " + manualDistance);
    	}
    	else {
    		distance = 48.0; //Arbitrary but hopefully reasonable value for "punting"...
    		Robot.dbgPrintln("No target found; punting with default value of " + distance); 
    	}
    	return distance;
    }

    // Use only for non-PID debug/bringup of the turret
    public void directDrive(double input) {
    	turretTurner.changeControlMode(TalonControlMode.PercentVbus); // Non-PID voltage based drive
    	turretTurner.set(input);
    }
    
    // Accessors for turret Commands like TurretWithJoystick.  Units are in rotations
    public double getLeftLimit() { return m_reverseSoftLimit; }
    public double getRightLimit() { return m_forwardSoftLimit; }

    public void cameraLightOn(boolean onState) {
    	// If onState is true, turn the camera light relay on.
    	// Otherwise, turn it off.
    	// If the light doesn't light up, try reversing the Direction (and therefore the voltage) to be .kReverse
    	cameraLightRelay.setDirection(Relay.Direction.kForward);
    	if (onState) {
    		cameraLightRelay.set(Relay.Value.kOn);
    	}
    	else {
    		cameraLightRelay.set(Relay.Value.kOff);
    	}
    	// Print the new state of the light to the SmartDashboard
		SmartDashboard.putBoolean("Boiler Camera Light On", onState);
    }

    //----------------------------------
    // Member Variables
    //----------------------------------
    private boolean m_visionEnabled = false; // Is the turret active?
    private double m_reverseSoftLimit = 0.0; // Soft limit in rotations
    private double m_forwardSoftLimit = 30/360; // Assume 30 degree max, with left side at zero.
	NetworkTable m_boilerTable;
    StringBuilder m_sb = new StringBuilder(); // class for building up strings across multiple code lines
	
	
    //----------------------------------
    // Constants
    //----------------------------------
	public static final double m_xRes = 640; // this is the maximum resolution in pixels for the x (horizontal) direction-- determined by how the vision pipeline is implemented.
	private static double m_cameraTheta = 30.521; // Empirically determined for Microsoft LifeCam3000 for 2017
	private static double m_targetWidthInches = 15; //Target tape is wrapped around a 15" diameter tube, so to the camera will appear 15" wide
	// This is the offset (in PIXELS) that we need to compensate between the camera center and the robot shooting centered.
	// You can determine this empirically by getting the robot to shoot perfectly and then reading the raw Xpos from the vision system...
	// (This can be overridden by the SmartDashboard)
	private static double m_targetCenterOffset = 0;    //(+1 means the robot is really centered when the image center is 1 pixel to the right of dead center xRes/2)
}

